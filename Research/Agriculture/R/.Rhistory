som_grid <- somgrid(xdim = 20, ydim=20, topo="hexagonal")
# Finally, train the SOM, options for the number of iterations,
# the learning rates, and the neighbourhood are available
som_model <- som(data_train_matrix,
grid=som_grid,
rlen=100,
alpha=c(0.05,0.01),
keep.data = TRUE,
n.hood=“circular” )
# Finally, train the SOM, options for the number of iterations,
# the learning rates, and the neighbourhood are available
som_model <- som(data_train_matrix,
grid=som_grid,
rlen=100,
alpha=c(0.05,0.01),
keep.my_data = TRUE,
n.hood=“circular” )
# Finally, train the SOM, options for the number of iterations,
# the learning rates, and the neighbourhood are available
som_model <- som(data_train_matrix,
grid=som_grid,
rlen=100,
alpha=c(0.05,0.01),
keep.my_data = TRUE,
n.hood=circular )
# Finally, train the SOM, options for the number of iterations,
# the learning rates, and the neighbourhood are available
som_model <- som(data_train_matrix,
grid=som_grid,
rlen=100,
alpha=c(0.05,0.01),
keep.my_data = TRUE,
n.hood='circular' )
# Finally, train the SOM, options for the number of iterations,
# the learning rates, and the neighbourhood are available
som_model <- som(data_train_matrix,
grid=som_grid,
rlen=100,
alpha=c(0.05,0.01),
keep.data = TRUE,
n.hood='circular' )
# Finally, train the SOM, options for the number of iterations,
# the learning rates, and the neighbourhood are available
som_model <- som(data_train_matrix, grid=som_grid, rlen=100, alpha=c(0.05,0.01), keep.data = TRUE, n.hood='circular' )
# Finally, train the SOM, options for the number of iterations,
# the learning rates, and the neighbourhood are available
som_model <- som(data_train_matrix, grid=som_grid, rlen=100, alpha=c(0.05,0.01), keep.data = TRUE, n.hood="circular" )
# Finally, train the SOM, options for the number of iterations,
# the learning rates, and the neighbourhood are available
som_model <- som(data_train_matrix, grid=som_grid, rlen=100, alpha=c(0.05,0.01), keep.data = TRUE, n.hood="circular")
# Finally, train the SOM, options for the number of iterations,
# the learning rates, and the neighbourhood are available
som_model <- som(data_train_matrix, grid=som_grid, rlen=100, alpha=c(0.05,0.01), keep.data = TRUE, n.hood="circular")
# Finally, train the SOM, options for the number of iterations,
# the learning rates, and the neighbourhood are available
som_model <- som(data_train_matrix, grid=som_grid, rlen=100, alpha=c(0.05,0.01), keep.data = TRUE)
, n.hood="circular"
# Finally, train the SOM, options for the number of iterations,
# the learning rates, and the neighbourhood are available
som_model <- som(data_train_matrix, grid=som_grid, rlen=100, alpha=c(0.05,0.01), keep.data = TRUE, n.hood="circular")
library(readxl)
#library(tseries)
my_data <- read.csv("aman_1.csv")
# Load the kohonen package
require(kohonen)
# Create a training data set (rows are samples, columns are variables
# Here I am selecting a subset of my variables available in "data"
data_train <- my_data[, c(2,3,4,5,6,7,8)]
# Change the data frame with training data to a matrix
# Also center and scale all variables to give them equal importance during
# the SOM training process.
data_train_matrix <- as.matrix(scale(data_train))
# Create the SOM Grid - you generally have to specify the size of the
# training grid prior to training the SOM. Hexagonal and Circular
# topologies are possible
som_grid <- somgrid(xdim = 20, ydim=20, topo="hexagonal")
# Finally, train the SOM, options for the number of iterations,
# the learning rates, and the neighbourhood are available
som_model <- som(data_train_matrix, grid=som_grid, rlen=100, alpha=c(0.05,0.01), keep.data = TRUE)
# Finally, train the SOM, options for the number of iterations,
# the learning rates, and the neighbourhood are available
som_model <- som(data_train_matrix, grid=som_grid, rlen=100, alpha=c(0.05,0.01), keep.data = TRUE, n.hood="circular")
# Finally, train the SOM, options for the number of iterations,
# the learning rates, and the neighbourhood are available
som_model <- som(data_train_matrix, grid=som_grid, rlen=100, alpha=c(0.05,0.01), keep.data = TRUE)
View(data_train)
View(data_train)
View(data_train_matrix)
View(data_train_matrix)
# Create the SOM Grid - you generally have to specify the size of the
# training grid prior to training the SOM. Hexagonal and Circular
# topologies are possible
som_grid <- somgrid(xdim = 7, ydim=7, topo="hexagonal")
# Finally, train the SOM, options for the number of iterations,
# the learning rates, and the neighbourhood are available
som_model <- som(data_train_matrix, grid=som_grid, rlen=100, alpha=c(0.05,0.01), keep.data = TRUE)
plot(som_model, type="changes")
plot(som_model, type="count")
plot(som_model, type="dist.neighbours")
plot(som_model, type="codes")
plot(som_model, type = "property", property = som_model$codes[,4], main=names(som_model$data)[4], palette.name=coolBlueHotRed)
coolBlueHotRed <- function(n, alpha = 1) {rainbow(n, end=4/6, alpha=alpha)[n:1]}
plot(som_model, type = "property", property = som_model$codes[,4], main=names(som_model$data)[4], palette.name=coolBlueHotRed)
plot(som_model, type = "property", property = som_model$codes[,7], main=names(som_model$data)[4], palette.name=coolBlueHotRed)
dim(som_model$codes)
som_model$codes
plot(som_model, type = "property", property = som_model$codes[,1], main=names(som_model$data)[4], palette.name=coolBlueHotRed)
plot(som_model, type = "property", property = som_model$codes[,2], main=names(som_model$data)[4], palette.name=coolBlueHotRed)
plot(som_model, type = "property", property = som_model$codes[,49], main=names(som_model$data)[4], palette.name=coolBlueHotRed)
plot(som_model, type = "property", property = som_model$codes, main=names(som_model$data)[4], palette.name=coolBlueHotRed)
plot(som_model, type = "property", property = som_model$codes[,7], main=names(som_model$data)[4], palette.name=coolBlueHotRed)
plot(som_model, type = "property", property = som_model$codes[49,7], main=names(som_model$data)[4], palette.name=coolBlueHotRed)
plot(som_model, type = "property", property = som_model$codes[,8], main=names(som_model$data)[4], palette.name=coolBlueHotRed)
som_model$codes
plot(som_model, type = "property", property = som_model$codes[,7], main=names(som_model$data)[4], palette.name=coolBlueHotRed)
dim(som_model$codes)
plot(som_model, type = "property", property = som_model$codes[,7], main=names(som_model$data)[4], palette.name=coolBlueHotRed)
x <- 1:12 ;
dim(x)
som_model$codes
plot(som_model, type = "property", property = som_model$codes[,7], main=names(som_model$data)[4], palette.name=coolBlueHotRed)
som_model$data
plot(som_model, type = "property", property = som_model$codes[,7], main=names(som_model$data)[7], palette.name=coolBlueHotRed)
plot(som_model, type = "property", property = som_model$codes[,], main=names(som_model$data)[4], palette.name=coolBlueHotRed)
>dim(x) <- c(2,5)
dim(x) <- c(2,5)
dim(x) <- c(2,6)
dim(x)
x[,2]
x[,1]
x[,3]
plot(som_model, type = "property", property = som_model$codes[,:7], main=names(som_model$data)[4], palette.name=coolBlueHotRed)
plot(som_model, type = "property", property = som_model$codes[,7], main=names(som_model$data)[4], palette.name=coolBlueHotRed)
x[2,6]
plot(som_model, type = "property", property = som_model$codes, main=names(som_model$data)[4], palette.name=coolBlueHotRed)
plot(som_model, type = "property", property = som_model$codes[,1:7], main=names(som_model$data)[4], palette.name=coolBlueHotRed)
x[,1:2]
x[,1:6]
plot(som_model, type = "property", property = som_model$codes[,1:7], main=names(som_model$data)[1:49,1:7], palette.name=coolBlueHotRed)
plot(som_model, type="changes")
plot(som_model, type="count")
plot(som_model, type="dist.neighbours")
plot(som_model, type="codes")
coolBlueHotRed <- function(n, alpha = 1) {rainbow(n, end=4/6, alpha=alpha)[n:1]}
plot(som_model, type = "property", property = som_model$codes[,1:7], main=names(som_model$data)[1:49,1:7], palette.name=coolBlueHotRed)
x[4]
x[43]
x[3]
x[1]
x[6]
x[7]
x[8]
x[12]
x[13]
#library(tseries)
my_data <- read.csv("aman_1.csv")
# Load the kohonen package
require(kohonen)
# Create a training data set (rows are samples, columns are variables
# Here I am selecting a subset of my variables available in "data"
data_train <- my_data[, c(2,3,4,5,6,7,8)]
# Change the data frame with training data to a matrix
# Also center and scale all variables to give them equal importance during
# the SOM training process.
data_train_matrix <- as.matrix(scale(data_train))
# Create the SOM Grid - you generally have to specify the size of the
# training grid prior to training the SOM. Hexagonal and Circular
# topologies are possible
som_grid <- somgrid(xdim = 7, ydim=7, topo="hexagonal")
# Finally, train the SOM, options for the number of iterations,
# the learning rates, and the neighbourhood are available
som_model <- som(data_train_matrix, grid=som_grid, rlen=100, alpha=c(0.05,0.01), keep.data = TRUE)
plot(som_model, type="changes")
plot(som_model, type="count")
plot(som_model, type="dist.neighbours")
plot(som_model, type="codes")
coolBlueHotRed <- function(n, alpha = 1) {rainbow(n, end=4/6, alpha=alpha)[n:1]}
plot(som_model, type = "property", property = som_model$codes[,1:7], main=names(som_model$data)[1:49,1:7], palette.name=coolBlueHotRed)
plot(som_model, type = "property", property = som_model$codes[,7], main=names(som_model$data)[1:49,1:7], palette.name=coolBlueHotRed)
var <- 2 #define the variable to plot
var_unscaled <- aggregate(as.numeric(data_train[,var]), by=list(som_model$unit.classif), FUN=mean, simplify=TRUE)[,2]
plot(som_model, type = "property", property=var_unscaled, main=names(data_train)[var], palette.name=coolBlueHotRed)
mydata <- som_model$codes
wss <- (nrow(mydata)-1)*sum(apply(mydata,2,var))
for (i in 2:15) {
wss[i] <- sum(kmeans(mydata, centers=i)$withinss)
}
plot(wss)
## use hierarchical clustering to cluster the codebook vectors
som_cluster <- cutree(hclust(dist(som_model$codes)), 6)
# plot these results:
plot(som_model, type="mapping", bgcol = pretty_palette[som_cluster], main = "Clusters")
add.cluster.boundaries(som_model, som_cluster)
plot(som_model, type = "property", property = som_model$codes[,7], main=names(som_model$data)[1:49,1:7], palette.name=coolBlueHotRed)
plot(som_model, type = "property", property = som_model$codes, main=names(som_model$data)[1:49,1:7], palette.name=coolBlueHotRed)
plot(som_model, type = "property", property = som_model$codes[,7], main=names(som_model$data)[1:49,1:7], palette.name=coolBlueHotRed)
plot(som_model, type = "property", property = som_model$codes[NULL], main=names(som_model$data)[1:49,1:7], palette.name=coolBlueHotRed)
som_model$codes[,1:7]
som_model$codes
View(som_model)
View(som_model)
plot(som_model, type = "property", property = som_model$codes[,13], main=names(som_model$data)[1:49,1:7], palette.name=coolBlueHotRed)
plot(som_model, type = "property", property = som_model$codes[,1], main=names(som_model$data)[1:49,1:7], palette.name=coolBlueHotRed)
#library(readxl)
#library(tseries)
my_data <- read.csv("aman_1.csv")
# Load the kohonen package
require(kohonen)
# Create a training data set (rows are samples, columns are variables
# Here I am selecting a subset of my variables available in "data"
data_train <- my_data[, c(2,3,4,5,6,7,8)]
# Change the data frame with training data to a matrix
# Also center and scale all variables to give them equal importance during
# the SOM training process.
data_train_matrix <- as.matrix(scale(data_train))
# Create the SOM Grid - you generally have to specify the size of the
# training grid prior to training the SOM. Hexagonal and Circular
# topologies are possible
som_grid <- somgrid(xdim = 7, ydim=7, topo="hexagonal")
# Finally, train the SOM, options for the number of iterations,
# the learning rates, and the neighbourhood are available
som_model <- som(data_train_matrix, grid=som_grid, rlen=100, alpha=c(0.05,0.01), keep.data = TRUE)
plot(som_model, type="changes")
plot(som_model, type="count")
plot(som_model, type="dist.neighbours")
plot(som_model, type="codes")
coolBlueHotRed <- function(n, alpha = 1) {rainbow(n, end=4/6, alpha=alpha)[n:1]}
plot(som_model, type = "property", property = som_model$codes[,1], main=names(som_model$data)[1:49,1:7], palette.name=coolBlueHotRed)
som_model$codes
#library(readxl)
#library(tseries)
my_data <- read.csv("aman_1.csv")
# Load the kohonen package
require(kohonen)
# Create a training data set (rows are samples, columns are variables
# Here I am selecting a subset of my variables available in "data"
data_train <- my_data[, c(2,3,4,5,6,7,8)]
# Change the data frame with training data to a matrix
# Also center and scale all variables to give them equal importance during
# the SOM training process.
data_train_matrix <- as.matrix(scale(data_train))
# Create the SOM Grid - you generally have to specify the size of the
# training grid prior to training the SOM. Hexagonal and Circular
# topologies are possible
som_grid <- somgrid(xdim = 7, ydim=7, topo="hexagonal")
# Finally, train the SOM, options for the number of iterations,
# the learning rates, and the neighbourhood are available
som_model <- som(data_train_matrix, grid=som_grid, rlen=100, alpha=c(0.05,0.01), keep.data = TRUE)
plot(som_model, type="changes")
plot(som_model, type="count")
plot(som_model, type="dist.neighbours")
plot(som_model, type="codes")
coolBlueHotRed <- function(n, alpha = 1) {rainbow(n, end=4/6, alpha=alpha)[n:1]}
plot(som_model, type = "property", property = som_model$codes[,1], main=names(som_model$data)[1:49,1:7], palette.name=coolBlueHotRed)
som_model$codes
dim(som_model$codes)
som_model
View(som_model)
View(som_model)
x = [1 2 3]
x <- [1 2 3]
"c" = 1:3
c
length(c)
View(x)
View(x)
length(som_model$codes)
plot(som_model, type = "property", property = som_model$codes[,1], main=names(som_model$data)[1:49,1:7], palette.name=coolBlueHotRed)
plot(som_model, type = "property", property = som_model$codes[1], main=names(som_model$data)[1:49,1:7], palette.name=coolBlueHotRed)
plot(som_model, type = "property", property = som_model$codes[1,], main=names(som_model$data)[1:49,1:7], palette.name=coolBlueHotRed)
,
plot(som_model, type = "property", property = som_model$codes[,1], main=names(som_model$data)[1:49,1:7], palette.name=coolBlueHotRed)
### LOAD LIBRARIES - install with:
#install.packages(c("kohonen", "dummies", "ggplot2", "maptools", "sp", "reshape2", "rgeos"))
library(kohonen)
library(dummies)
install.packages("dummies")
library(dummies)
### LOAD LIBRARIES - install with:
#install.packages(c("kohonen", "dummies", "ggplot2", "maptools", "sp", "reshape2", "rgeos"))
library(kohonen)
library(dummies)
library(ggplot2)
library(sp)
library(maptools)
install.packages("maptools")
install.packages("maptools")
library(maptools)
gpclibPermit()
gpclibPermit()
install.packages("gpclib")
library(maptools)
library(reshape2)
library(rgeos)
install.packages("rgeos")
install.packages("rgeos")
library(rgeos)
# Colour palette definition
pretty_palette <- c("#1f77b4", '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2')
#options to explore a few different map types:
small_areas <- TRUE  # Choose between Small Areas or Electoral Districts
filter <- TRUE       # choose to filter output to Dublin area only (good for small areas)
if (small_areas){
data_raw <- read.csv("./census_data/AllThemesTablesSA.csv")
ireland_map <- readShapePoly('./boundary_files/Census2011_Small_Areas_generalised20m.shp')
#Note that the map polygons and the census data are not in the same order - rearrangement:
data_raw <- data_raw[match(ireland_map$SMALL_AREA, data_raw$GEOGDESC),]
idcol="GEOGDESC"
} else {
data_raw <- read.csv("./census_data/AllThemesTablesED.csv")
names(data_raw)[1] <- "GEOGID"
ireland_map <- readShapePoly('./boundary_files/Census2011_Electoral_Divisions_generalised20m.shp')
ireland_map$CSOED <- paste0("E", ireland_map$CSOED)
#Note that the map polygons and the census data are not in the same order
data_raw <- data_raw[match(ireland_map$CSOED, data_raw$GEOGID),]
idcol="GEOGID"
}
#Filter now for certain counties
if (filter){
counties <- c("Fingal", "Dublin City", "South Dublin", "Dún Laoghaire-Rathdown")
plot_idx <- ireland_map$COUNTYNAME %in% counties
data_raw <- data_raw[plot_idx,]
ireland_map <- ireland_map[plot_idx,]
rm(counties, filter, plot_idx)
}
#convert the data from summations to percentages such
#that the characteristics of each area will be comparable.
source("convertCSOdata.R")
data <- convertCSOdata(data_raw, idcol=idcol)
#Create SOM for Census data - simple as data is well behaved.
#remove incomplete samples:
incompletes <- which(!complete.cases(data))
#where the avr_education_level is NaN - replace with mean
data$avr_education_level[incompletes] <- mean(data$avr_education_level, na.rm=TRUE)
#recalculate after adjustment
incompletes <- which(!complete.cases(data))
if (length(incompletes) > 0){
print(paste0("Removing ", length(incompletes), " data points that have missing values."))
data <- data[-incompletes, ]
}
rm(incompletes)
#choose the variables with which to train the SOM
data_train <- data[, c(2,4,5,8)]
# now train the SOM using the Kohonen method
data_train_matrix <- as.matrix(scale(data_train))
names(data_train_matrix) <- names(data_train)
require(kohonen)
if (small_areas){
# larger grid for the small areas example (more samples)
som_grid <- somgrid(xdim = 20, ydim=20, topo="hexagonal")
} else {
som_grid <- somgrid(xdim = 10, ydim=10, topo="hexagonal")
}
# Train the SOM model!
system.time(som_model <- som(data_train_matrix,
grid=som_grid,
rlen=100,
alpha=c(0.05,0.01),
n.hood = "circular",
keep.data = TRUE ))
# Train the SOM model!
system.time(som_model <- som(data_train_matrix,
grid=som_grid,
rlen=100,
alpha=c(0.05,0.01),
keep.data = TRUE ))
rm(som_grid, data_train_matrix)
## custom palette as per kohonen package (not compulsory)
source('coolBlueHotRed.R')
plot(som_model, type = "changes")
#counts within nodes
plot(som_model, type = "counts", main="Node Counts", palette.name=coolBlueHotRed)
#map quality
plot(som_model, type = "quality", main="Node Quality/Distance", palette.name=coolBlueHotRed)
#neighbour distances
plot(som_model, type="dist.neighbours", main = "SOM neighbour distances", palette.name=grey.colors)
#code spread
plot(som_model, type = "codes")
# Plot the heatmap for a variable at scaled / normalised values
var <- 2
plot(som_model, type = "property", property = som_model$codes[,var], main=names(som_model$data)[var], palette.name=coolBlueHotRed)
#library(readxl)
#library(tseries)
my_data <- read.csv("aman_1.csv")
# Load the kohonen package
require(kohonen)
# Create a training data set (rows are samples, columns are variables
# Here I am selecting a subset of my variables available in "data"
data_train <- my_data[, c(2,3,4,5,6,7,8)]
# Change the data frame with training data to a matrix
# Also center and scale all variables to give them equal importance during
# the SOM training process.
data_train_matrix <- as.matrix(scale(data_train))
# Create the SOM Grid - you generally have to specify the size of the
# training grid prior to training the SOM. Hexagonal and Circular
# topologies are possible
som_grid <- somgrid(xdim = 7, ydim=7, topo="hexagonal")
# Finally, train the SOM, options for the number of iterations,
# the learning rates, and the neighbourhood are available
som_model <- som(data_train_matrix, grid=som_grid, rlen=100, alpha=c(0.05,0.01), keep.data = TRUE)
plot(som_model, type="changes")
plot(som_model, type="count")
plot(som_model, type="dist.neighbours")
plot(som_model, type="codes")
coolBlueHotRed <- function(n, alpha = 1) {rainbow(n, end=4/6, alpha=alpha)[n:1]}
plot(som_model, type = "property", property = som_model$codes[,1], main=names(som_model$data)[1:49,1:7], palette.name=coolBlueHotRed)
View(som_model)
View(som_model)
plot(som_model, type = "property", property = som_model$codes[[1]], main=names(som_model$data)[1:49,1:7], palette.name=coolBlueHotRed)
var <- 2 #define the variable to plot
var_unscaled <- aggregate(as.numeric(data_train[,var]), by=list(som_model$unit.classif), FUN=mean, simplify=TRUE)[,2]
plot(som_model, type = "property", property=var_unscaled, main=names(data_train)[var], palette.name=coolBlueHotRed)
plot(som_model, type = "property", property = som_model$codes[[1]], main=names(som_model$data)[1:49,1:7], palette.name=coolBlueHotRed)
var <- 2 #define the variable to plot
var_unscaled <- aggregate(as.numeric(data_train[,var]), by=list(som_model$unit.classif), FUN=mean, simplify=TRUE)[,2]
plot(som_model, type = "property", property=var_unscaled, main=names(data_train)[var], palette.name=coolBlueHotRed)
mydata <- som_model$codes
wss <- (nrow(mydata)-1)*sum(apply(mydata,2,var))
for (i in 2:15) {
wss[i] <- sum(kmeans(mydata, centers=i)$withinss)
}
mydata <- som_model$codes
wss <- (nrow(mydata)-1)*sum(apply(mydata,2,var))
mydata <- som_model$codes
wss <- (nrow(mydata)-1)*sum(apply(mydata,2,var))
mydata <- som_model$codes[[1]]
wss <- (nrow(mydata)-1)*sum(apply(mydata,2,var))
for (i in 2:15) {
wss[i] <- sum(kmeans(mydata, centers=i)$withinss)
}
plot(wss)
## use hierarchical clustering to cluster the codebook vectors
som_cluster <- cutree(hclust(dist(som_model$codes)), 6)
## use hierarchical clustering to cluster the codebook vectors
som_cluster <- cutree(hclust(dist(som_model$codes[[1]])), 6)
# plot these results:
plot(som_model, type="mapping", bgcol = pretty_palette[som_cluster], main = "Clusters")
# plot these results:
pretty_palette <- c("#1f77b4","#ff7f0e","#2ca02c", "#d62728","#9467bd","#8c564b","#e377c2")
plot(som_model, type="mapping", bgcol = pretty_palette[som_cluster], main = "Clusters")
add.cluster.boundaries(som_model, som_cluster)
# Finally, train the SOM, options for the number of iterations,
# the learning rates, and the neighbourhood are available
som_model <- som(data_train_matrix, grid=som_grid, rlen=100, alpha=c(0.05,0.01), keep.data = TRUE)
plot(som_model, type="changes")
plot(som_model, type="count")
plot(som_model, type="dist.neighbours")
plot(som_model, type="codes")
coolBlueHotRed <- function(n, alpha = 1) {rainbow(n, end=4/6, alpha=alpha)[n:1]}
plot(som_model, type = "property", property = som_model$codes[[1]], main=names(som_model$data)[1:49,1:7], palette.name=coolBlueHotRed)
var <- 2 #define the variable to plot
var_unscaled <- aggregate(as.numeric(data_train[,var]), by=list(som_model$unit.classif), FUN=mean, simplify=TRUE)[,2]
plot(som_model, type = "property", property=var_unscaled, main=names(data_train)[var], palette.name=coolBlueHotRed)
mydata <- som_model$codes[[1]]
wss <- (nrow(mydata)-1)*sum(apply(mydata,2,var))
for (i in 2:15) {
wss[i] <- sum(kmeans(mydata, centers=i)$withinss)
}
plot(wss)
## use hierarchical clustering to cluster the codebook vectors
som_cluster <- cutree(hclust(dist(som_model$codes[[1]])), 6)
# plot these results:
pretty_palette <- c("#1f77b4","#ff7f0e","#2ca02c", "#d62728","#9467bd","#8c564b","#e377c2")
plot(som_model, type="mapping", bgcol = pretty_palette[som_cluster], main = "Clusters")
add.cluster.boundaries(som_model, som_cluster)
#library(readxl)
#library(tseries)
my_data <- read.csv("Agri.csv")
# Load the kohonen package
require(kohonen)
# Create a training data set (rows are samples, columns are variables
# Here I am selecting a subset of my variables available in "data"
data_train <- my_data[, c(2,3,4,5,6,7,8)]
# Change the data frame with training data to a matrix
# Also center and scale all variables to give them equal importance during
# the SOM training process.
data_train_matrix <- as.matrix(scale(data_train))
# Create the SOM Grid - you generally have to specify the size of the
# training grid prior to training the SOM. Hexagonal and Circular
# topologies are possible
som_grid <- somgrid(xdim = 14, ydim=11, topo="hexagonal")
# Finally, train the SOM, options for the number of iterations,
# the learning rates, and the neighbourhood are available
som_model <- som(data_train_matrix, grid=som_grid, rlen=100, alpha=c(0.05,0.01), keep.data = TRUE)
# Create the SOM Grid - you generally have to specify the size of the
# training grid prior to training the SOM. Hexagonal and Circular
# topologies are possible
som_grid <- somgrid(xdim = 12, ydim=12, topo="hexagonal")
# Finally, train the SOM, options for the number of iterations,
# the learning rates, and the neighbourhood are available
som_model <- som(data_train_matrix, grid=som_grid, rlen=100, alpha=c(0.05,0.01), keep.data = TRUE)
plot(som_model, type="changes")
plot(som_model, type="count")
plot(som_model, type="dist.neighbours")
plot(som_model, type="codes")
coolBlueHotRed <- function(n, alpha = 1) {rainbow(n, end=4/6, alpha=alpha)[n:1]}
plot(som_model, type = "property", property = som_model$codes[[1]], main=names(som_model$data)[1:49,1:7], palette.name=coolBlueHotRed)
var <- 2 #define the variable to plot
var_unscaled <- aggregate(as.numeric(data_train[,var]), by=list(som_model$unit.classif), FUN=mean, simplify=TRUE)[,2]
plot(som_model, type = "property", property=var_unscaled, main=names(data_train)[var], palette.name=coolBlueHotRed)
mydata <- som_model$codes[[1]]
wss <- (nrow(mydata)-1)*sum(apply(mydata,2,var))
for (i in 2:15) {
wss[i] <- sum(kmeans(mydata, centers=i)$withinss)
}
plot(wss)
## use hierarchical clustering to cluster the codebook vectors
som_cluster <- cutree(hclust(dist(som_model$codes[[1]])), 6)
# plot these results:
pretty_palette <- c("#1f77b4","#ff7f0e","#2ca02c", "#d62728","#9467bd","#8c564b","#e377c2")
plot(som_model, type="mapping", bgcol = pretty_palette[som_cluster], main = "Clusters")
add.cluster.boundaries(som_model, som_cluster)
